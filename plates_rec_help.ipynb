{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from openalpr import Alpr\n",
    "\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'C')\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpr =  Alpr(\"us\", \"/etc/openalpr/openalpr.conf\", \"/usr/local/src/openalpr/openalpr/runtime_data/\")\n",
    "\n",
    "if not alpr.is_loaded():\n",
    "    print(\"Error loading OpenALPR\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 2092, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"g.jpg\", 1)\n",
    "print(img.shape)\n",
    "\n",
    "cv2.imshow(\"name\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (747-573)/(585-496)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PERSPECTIVE TRANSFORM\n",
    "\n",
    "rows, cols = img.shape\n",
    "\n",
    "e = 200\n",
    "#pts1 = np.float32([[573-(e*a),496-e],[747+(e*a),495-e],[570-(e*a),585+e],[749+(e*a),589+e]])\n",
    "pts1 = np.float32([[646-(e*a),455-e],[816+(e*a),453-e],[652-(e*a),540+e],[818+(e*a),547+e]])\n",
    "pts2 = np.float32([[100,100],[1992,100],[100,1012],[1992,1012]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "img_new_perspective = cv2.warpPerspective(img, M ,(cols,rows))\n",
    "\n",
    "cv2.imshow(\"name\", img_new_perspective)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PERSPECTIVE TRANSFORM\n",
    "\n",
    "rows, cols = img.shape\n",
    "\n",
    "e = 200\n",
    "pts1 = np.float32([[573-(e*a),496-e],[747+(e*a),495-e],[570-(e*a),585+e],[749+(e*a),589+e]])\n",
    "#pts1 = np.float32([[573,496],[747,495],[570,585],[749,589]])\n",
    "pts2 = np.float32([[100,100],[1992,100],[100,1012],[1992,1012]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "img_new_perspective = cv2.warpPerspective(img, M ,(cols,rows))\n",
    "\n",
    "cv2.imshow(\"name\", img_new_perspective)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLUR\n",
    "\n",
    "img_medianBlur = cv2.medianBlur(img, 3)\n",
    "cv2.imshow(\"name\", img_medianBlur)\n",
    "\n",
    "#img_GaussianBlur = cv2.GaussianBlur(img_new_perspective, (3,3), 0.4)\n",
    "#cv2.imshow(\"name\", img_GaussianBlur)\n",
    "\n",
    "#img_Blur = cv2.blur(img_new_perspective, (23,23))\n",
    "#cv2.imshow(\"name\", img_blur)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST THRESHOLD OF THE BLURRED IMAGE\n",
    "\n",
    "#ret, thr1 = cv2.threshold(img_medianBlur, 95, 255, cv2.THRESH_BINARY_INV)\n",
    "##ret, thr1 = cv2.threshold(img_medianBlur, 95, 255, cv2.THRESH_BINARY)\n",
    "###ret, thr1 = cv2.threshold(img_medianBlur, 150, 255, cv2.THRESH_TRUNC)\n",
    "ret, thr1 = cv2.threshold(img_medianBlur, 89, 255, cv2.THRESH_TOZERO)\n",
    "#####ret, thr1 = cv2.threshold(img_medianBlur, 114, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "cv2.imshow(\"name\", thr1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hist_eq = cv2.equalizeHist(img)\n",
    "\n",
    "cv2.imshow(\"name\", img_hist_eq)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows the image\n",
    "cv2.imshow(\"name.jpg\", img_hist_eq)\n",
    "\n",
    "#creates waitKey\n",
    "kk = cv2.waitKey(0)\n",
    "\n",
    "if kk == 27: #esc key\n",
    "    cv2.destroyAllWindows()\n",
    "elif kk == ord(\"s\"): #press s key\n",
    "    cv2.imwrite(\"test_a.jpg\", img_hist_eq)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.line(img,(296,534),(466,534),(255,0,0),5)\n",
    "cv2.line(img,(466,534),(485,645),(255,0,0),5)\n",
    "cv2.line(img,(485,645),(317,645),(255,0,0),5)\n",
    "cv2.line(img,(317,645),(296,534),(255,0,0),5)\n",
    "\n",
    "cv2.imshow(\"name\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video (un cuadro seleccionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plate #1\n",
      "          Plate   Confidence\n",
      "  -       BAY841   79.207649\n",
      "  -       8AY841   76.941948\n",
      "  -       BAYB41   75.620598\n",
      "  -       8AYB41   73.354897\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"carros.avi\")\n",
    "\n",
    "cuadro = 1\n",
    "\n",
    "#while cuadro < 1469:\n",
    "while cuadro < 107        \n",
    "    _ = cap.read()\n",
    "    cuadro += 1\n",
    "\n",
    "r, img_cuadro = cap.read()\n",
    "\n",
    "img_cuadro_copia = img_cuadro.copy()\n",
    "\n",
    "#cv2.imshow(\"cuadro\", img_cuadro)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "alpr.set_top_n(10)\n",
    "\n",
    "results = alpr.recognize_ndarray(img_cuadro)\n",
    "\n",
    "ii = 0\n",
    "for plate in results['results']:\n",
    "    ii += 1\n",
    "    print(\"Plate #%d\" % ii)\n",
    "    print(\"   %12s %12s\" % (\"Plate\", \"Confidence\"))\n",
    "    for candidate in plate['candidates']:\n",
    "        prefix = \"-\"\n",
    "        if candidate['matches_template']:\n",
    "            prefix = \"*\"\n",
    "\n",
    "        print(\"  %s %12s%12f\" % (prefix, candidate['plate'], candidate['confidence']))\n",
    "\n",
    "#while(True):\n",
    "    \n",
    "    #ret, frame = cap.read() #boolean, np.ndarray.\n",
    "    \n",
    "    #gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #frame_medianBlur = cv2.medianBlur(gray_frame, 3)\n",
    "    #frame_ret, frame_thr1 = cv2.threshold(frame_medianBlur, 89, 255, cv2.THRESH_TOZERO)\n",
    "    #frame_hist_eq = cv2.equalizeHist(frame_thr1)\n",
    "    #frame_edges = cv2.Canny(frame_hist_eq, 89, 255)\n",
    "    \n",
    "    #cv2.imshow(\"frame\", frame_hist_eq)\n",
    "    \n",
    "    #cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    #if cv2.waitKey(51) & 0xFF == ord(\"q\"):\n",
    "    #    break\n",
    "\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'version': 2,\n",
    " 'data_type': 'alpr_results',\n",
    " 'epoch_time': 1554241444311,\n",
    " 'img_width': 1280,\n",
    " 'img_height': 720,\n",
    " 'processing_time_ms': 209.494049,\n",
    " 'regions_of_interest': [{'x': 0, \n",
    "                          'y': 0, \n",
    "                          'width': 1280, \n",
    "                          'height': 720}],\n",
    " 'results': [{'plate': 'TGY860',\n",
    "              'confidence': 81.276688,\n",
    "              'matches_template': 0,\n",
    "              'plate_index': 0,\n",
    "              'region': '',\n",
    "              'region_confidence': 0,\n",
    "              'processing_time_ms': 16.660786,\n",
    "              'requested_topn': 10,\n",
    "              'coordinates': [{'x': 564, 'y': 217},\n",
    "                              {'x': 621, 'y': 218},\n",
    "                              {'x': 621, 'y': 247},\n",
    "                              {'x': 564, 'y': 246}\n",
    "                             ],\n",
    "              'candidates': [{'plate': 'TGY860', 'confidence': 81.276688, 'matches_template': 0},\n",
    "                             {'plate': 'TGT860', 'confidence': 81.057198, 'matches_template': 0},\n",
    "                             {'plate': '1TGY80', 'confidence': 79.989349, 'matches_template': 0},\n",
    "                             {'plate': 'IGY860', 'confidence': 79.922066, 'matches_template': 0},\n",
    "                             {'plate': '1TGT80', 'confidence': 79.769852, 'matches_template': 0},\n",
    "                             {'plate': 'IGT860', 'confidence': 79.702568, 'matches_template': 0},\n",
    "                             {'plate': '1GY860', 'confidence': 79.680977, 'matches_template': 0},\n",
    "                             {'plate': '1GT860', 'confidence': 79.461487, 'matches_template': 0},\n",
    "                             {'plate': '1TG860', 'confidence': 79.346725, 'matches_template': 0},\n",
    "                             {'plate': '1IGY80', 'confidence': 78.634727, 'matches_template': 0}\n",
    "                            ]\n",
    "             }\n",
    "            ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap.release()\n",
    "#alpr.unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAY841']\n",
      "[79.207649]\n"
     ]
    }
   ],
   "source": [
    "placas_cuadro_ii = []\n",
    "confianza_cuadro_ii = []\n",
    "\n",
    "for ii in range(3):\n",
    "    \n",
    "    a = results[\"results\"][0][\"candidates\"][ii][\"plate\"]\n",
    "    b = results[\"results\"][0][\"candidates\"][ii][\"confidence\"]\n",
    "    \n",
    "    if re.match(r\"^[A-Z]{3}[0-9]{3}$\", a):\n",
    "        placas_cuadro_ii.append(a)\n",
    "        confianza_cuadro_ii.append(b)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(placas_cuadro_ii)\n",
    "print(confianza_cuadro_ii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BAY841', 79.207649)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(placas_cuadro_ii, confianza_cuadro_ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAY841']\n",
      "BAY841\n"
     ]
    }
   ],
   "source": [
    "placa = results[\"results\"][0][\"plate\"]\n",
    "data = placa.split(None) #split string into a list\n",
    "print(data)\n",
    "print(placa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid :)\n"
     ]
    }
   ],
   "source": [
    "if re.match(r\"^[A-Z]{3}[0-9]{3}$\", placa):\n",
    "    print(\"Valid :)\")\n",
    "else:\n",
    "    print(\"Invalid :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BAY', '841']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placa_separada = [placa[i:i+3] for i in range(0, len(placa), 3)]\n",
    "placa_separada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAY <class 'str'>\n",
      "['B', 'A', 'Y'] <class 'str'>\n",
      "841 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "letras = placa_separada[0]\n",
    "numeros = placa_separada[1]\n",
    "\n",
    "letras_separadas = [letras[i:i+1] for i in range(0, len(letras), 1)]\n",
    "numeros_separadas = [numeros[i:i+1] for i in range(0, len(numeros), 1)]\n",
    "\n",
    "print(letras, type(letras))\n",
    "print(letras_separadas, type(letras))\n",
    "print(numeros, type(numeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "if (type(letras_separadas[0]) == str) & (type(letras_separadas[1]) == str) & (type(letras_separadas[2]) == str):\n",
    "    print(\"YES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "if (type(letras_separadas[0]) == str) & (type(letras_separadas[1]) == str) & (type(letras_separadas[2]) == str):\n",
    "    print(\"YES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BAY841'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"results\"][0][\"plate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 2,\n",
       " 'data_type': 'alpr_results',\n",
       " 'epoch_time': 1554488086451,\n",
       " 'img_width': 1280,\n",
       " 'img_height': 720,\n",
       " 'processing_time_ms': 302.305847,\n",
       " 'regions_of_interest': [{'x': 0, 'y': 0, 'width': 1280, 'height': 720}],\n",
       " 'results': [{'plate': 'BAY841',\n",
       "   'confidence': 79.207649,\n",
       "   'matches_template': 0,\n",
       "   'plate_index': 0,\n",
       "   'region': '',\n",
       "   'region_confidence': 0,\n",
       "   'processing_time_ms': 22.10911,\n",
       "   'requested_topn': 10,\n",
       "   'coordinates': [{'x': 395, 'y': 318},\n",
       "    {'x': 484, 'y': 326},\n",
       "    {'x': 482, 'y': 369},\n",
       "    {'x': 393, 'y': 361}],\n",
       "   'candidates': [{'plate': 'BAY841',\n",
       "     'confidence': 79.207649,\n",
       "     'matches_template': 0},\n",
       "    {'plate': '8AY841', 'confidence': 76.941948, 'matches_template': 0},\n",
       "    {'plate': 'BAYB41', 'confidence': 75.620598, 'matches_template': 0},\n",
       "    {'plate': '8AYB41', 'confidence': 73.354897, 'matches_template': 0}]}]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'plate': 'BAY841',\n",
       "  'confidence': 79.207649,\n",
       "  'matches_template': 0,\n",
       "  'plate_index': 0,\n",
       "  'region': '',\n",
       "  'region_confidence': 0,\n",
       "  'processing_time_ms': 22.10911,\n",
       "  'requested_topn': 10,\n",
       "  'coordinates': [{'x': 395, 'y': 318},\n",
       "   {'x': 484, 'y': 326},\n",
       "   {'x': 482, 'y': 369},\n",
       "   {'x': 393, 'y': 361}],\n",
       "  'candidates': [{'plate': 'BAY841',\n",
       "    'confidence': 79.207649,\n",
       "    'matches_template': 0},\n",
       "   {'plate': '8AY841', 'confidence': 76.941948, 'matches_template': 0},\n",
       "   {'plate': 'BAYB41', 'confidence': 75.620598, 'matches_template': 0},\n",
       "   {'plate': '8AYB41', 'confidence': 73.354897, 'matches_template': 0}]}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "placa_actual = results[\"results\"][0][\"plate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BAY841'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placa_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAY841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results[\"results\"][0][\"plate\"])\n",
    "type(results[\"results\"][0][\"plate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAA000'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placa_anterior = str(\"AAA000\")\n",
    "placa_anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not empty\n"
     ]
    }
   ],
   "source": [
    "if len(results[\"results\"])==0:\n",
    "    print(\"empty\")\n",
    "else:\n",
    "    print(\"not empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cuadro_copia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PONE LÍNEAS EN EL CUADRO SEGÚN LAS LOCATIONS DE LA PLACA SEGÚN alpr.\n",
    "\n",
    "img_location = img_cuadro_copia.copy()\n",
    "\n",
    "cv2.line(img_location,\n",
    "         (results[\"results\"][0][\"coordinates\"][0][\"x\"], results[\"results\"][0][\"coordinates\"][0][\"y\"]), \n",
    "         (results[\"results\"][0][\"coordinates\"][1][\"x\"], results[\"results\"][0][\"coordinates\"][1][\"y\"]),\n",
    "         (255,0,0), \n",
    "         5\n",
    "        )\n",
    "cv2.line(img_location,\n",
    "         (results[\"results\"][0][\"coordinates\"][1][\"x\"], results[\"results\"][0][\"coordinates\"][1][\"y\"]), \n",
    "         (results[\"results\"][0][\"coordinates\"][2][\"x\"], results[\"results\"][0][\"coordinates\"][2][\"y\"]),\n",
    "         (255,0,0), \n",
    "         5\n",
    "        )\n",
    "cv2.line(img_location,\n",
    "         (results[\"results\"][0][\"coordinates\"][2][\"x\"], results[\"results\"][0][\"coordinates\"][2][\"y\"]), \n",
    "         (results[\"results\"][0][\"coordinates\"][3][\"x\"], results[\"results\"][0][\"coordinates\"][3][\"y\"]),\n",
    "         (255,0,0), \n",
    "         5\n",
    "        )\n",
    "cv2.line(img_location,\n",
    "         (results[\"results\"][0][\"coordinates\"][3][\"x\"], results[\"results\"][0][\"coordinates\"][3][\"y\"]), \n",
    "         (results[\"results\"][0][\"coordinates\"][0][\"x\"], results[\"results\"][0][\"coordinates\"][0][\"y\"]),\n",
    "         (255,0,0), \n",
    "         5\n",
    "        )    \n",
    "\n",
    "cv2.imshow(\"location\", img_location)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LA PLACA AMPLIADA USANDO LAS LOCATIONS OBTENIDAS CON alpr.\n",
    "\n",
    "rows, cols, colors = img_cuadro_copia.shape\n",
    "\n",
    "#pts1 = np.float32([[573-(e*a),496-e],[747+(e*a),495-e],[570-(e*a),585+e],[749+(e*a),589+e]])\n",
    "pts1 = np.float32([[results[\"results\"][0][\"coordinates\"][0][\"x\"], results[\"results\"][0][\"coordinates\"][0][\"y\"] ],\n",
    "                   [results[\"results\"][0][\"coordinates\"][1][\"x\"], results[\"results\"][0][\"coordinates\"][1][\"y\"]],\n",
    "                   [results[\"results\"][0][\"coordinates\"][3][\"x\"], results[\"results\"][0][\"coordinates\"][3][\"y\"]], \n",
    "                   [results[\"results\"][0][\"coordinates\"][2][\"x\"], results[\"results\"][0][\"coordinates\"][2][\"y\"]] ])\n",
    "pts2 = np.float32([[0,0],[1280,0],[0,720],[1280,720]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "placa = cv2.warpPerspective(img_cuadro_copia, M ,(cols,rows))\n",
    "\n",
    "cv2.imshow(\"placa\", placa)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "alpr.unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "################# Imports ################\n",
    "##########################################\n",
    "import numpy as np\n",
    "import cv2\n",
    "from openalpr import Alpr\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'C')\n",
    "\n",
    "##########################################\n",
    "############ Some parameters #############\n",
    "##########################################\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "##########################################\n",
    "############### Start alpr ###############\n",
    "##########################################\n",
    "alpr =  Alpr(\"us\", \"/etc/openalpr/openalpr.conf\", \"/usr/local/src/openalpr/openalpr/runtime_data/\")\n",
    "\n",
    "if not alpr.is_loaded():\n",
    "    print(\"Error loading OpenALPR\")\n",
    "    sys.exit(1)\n",
    "\n",
    "alpr.set_top_n(10)\n",
    "\n",
    "##########################################\n",
    "############# Captura video ##############\n",
    "##########################################\n",
    "cap = cv2.VideoCapture(\"carros.avi\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    alpr.unload()\n",
    "    sys.exit(\"No abrió el video\")\n",
    "\n",
    "#########################################\n",
    "#########################################\n",
    "\n",
    "cuadros = []\n",
    "placas = []\n",
    "\n",
    "cuadro = 0\n",
    "\n",
    "while True:\n",
    "\n",
    "    # crea el objeto (bool, np.ndarray) presente en el cuadro del video.\n",
    "    ret_bool, img_cuadro = cap.read()\n",
    "    img_cuadro_copia = img_cuadro.copy() # copia del cuadro\n",
    "\n",
    "    # si no lee, pare.\n",
    "    if not ret_bool:\n",
    "        print(\"cap = cv2.VidepCapture.read() no sirvió.\")\n",
    "        break\n",
    "\n",
    "    # diccionario de resultados que se obtiene al usar alpr.\n",
    "    results = alpr.recognize_ndarray(img_cuadro)\n",
    "\n",
    "    ############################################################################\n",
    "    ############### pinta cuadro y placa en la placa detectada #################\n",
    "    ############################################################################\n",
    "    img_location = img_cuadro_copia.copy() #copia del cuadro copiado\n",
    "\n",
    "    \n",
    "    for una_placa in results[\"results\"]: # para cada placa detectada en el cuadro.\n",
    "        \n",
    "        # LÍNEAS #\n",
    "        for ii in range(3):\n",
    "            cv2.line(img_location,\n",
    "                 (una_placa[\"coordinates\"][ii%4][\"x\"], una_placa[\"coordinates\"][ii%4][\"y\"]), \n",
    "                 (una_placa[\"coordinates\"][(ii+1)%4][\"x\"], una_placa[\"coordinates\"][(ii+1)%4][\"y\"]),\n",
    "                 (255,0,0), \n",
    "                 5\n",
    "            )\n",
    "        # PLACA TOP CANDIDATE #\n",
    "        cv2.putText(img_location,\n",
    "                    una_placa[\"candidates\"][0][\"plate\"]+\" (confianza: \"+\n",
    "                    una_placa[\"candidates\"][0][\"confidence\"]+\")\"\n",
    "                    (una_placa[\"coordinates\"][0][\"x\"], una_placa[\"coordinates\"][0][\"y\"]),\n",
    "                    font, 1.0, (1, 1, 255),\n",
    "                    1\n",
    "        )\n",
    "\n",
    "#        candidatas_placa = []\n",
    "#        confianza_candidatas_del_cuadro = []\n",
    "#        \n",
    "#        for ii in range(10):\n",
    "#            \n",
    "#            a = una_placa[\"candidates\"][ii][\"plate\"]\n",
    "#            b = una_placa[\"candidates\"][ii][\"confidence\"]\n",
    "#            \n",
    "#            # REGEX # SI TIENE FORMA DE PLACA (TRES LETRAS MAYÚSCULAS, TRES NÚMEROS)\n",
    "#            if re.match(r\"^[A-Z]{3}[0-9]{3}$\", a):\n",
    "#                placas_cuadro_ii.append(a)\n",
    "#                confianza_cuadro_ii.append(b)     \n",
    "#            else:\n",
    "#                pass\n",
    "\n",
    "        ## Imprime en la consola el cuadro, la placa, y la confianza de esa placa.\n",
    "        #print(cuadro, una_placa[\"candidates\"][0], una_placa[\"confidence\"])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Pone el número del cuadro en la imagen.\n",
    "    cv2.putText(img_location, str(cuadro), (26, 621), font, 2.0, (0, 0, 255), 1)\n",
    "\n",
    "    cuadros.append(cuadro)\n",
    "    cuadro += 1\n",
    "\n",
    "    cv2.imshow(\"Video con placas\", img_location)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "alpr.unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b4f03563a3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mgray_frame_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mblurred_gray_frame_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_frame_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import re\n",
    "\n",
    "from openalpr import Alpr\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'C')\n",
    "\n",
    "#initialize alpr object.\n",
    "alpr =  Alpr(\"us\", \"/etc/openalpr/openalpr.conf\", \"/usr/local/src/openalpr/openalpr/runtime_data/\")\n",
    "\n",
    "if not alpr.is_loaded():\n",
    "    print(\"Error loading OpenALPR\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# initialize cv2 video object.\n",
    "cap = cv2.VideoCapture(\"carros.avi\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    alpr.unload()\n",
    "    sys.exit(\"No abrió el video\")\n",
    "\n",
    "# parameters.\n",
    "alpr.set_top_n(10)\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "delta_threshold = 10\n",
    "min_area = 2800\n",
    "\n",
    "\n",
    "# the things to do.\n",
    "frame = 1\n",
    "prev_frame = None\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret_bool, frame_img_orig = cap.read()\n",
    "        \n",
    "    if not ret_bool:\n",
    "        print(\"no hay cuadro\")\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "    #MOTION DETECTOR.\n",
    "    frame_img = frame_img_orig.copy()\n",
    "\n",
    "    gray_frame_img = cv2.cvtColor(frame_img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_gray_frame_img = cv2.GaussianBlur(gray_frame_img, (15, 15), 0)\n",
    "    \n",
    "cap.release()\n",
    "alpr.unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /io/opencv/modules/core/src/arithm.cpp:663: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4c5ceb8305bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m#operations for motion detector to work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#necesary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mframeDelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblurred_gray_frame_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m#for it to work better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /io/opencv/modules/core/src/arithm.cpp:663: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "    #operations for motion detector to work\n",
    "    #necesary\n",
    "    frameDelta = cv2.absdiff(blurred_gray_frame_img, prev_frame)\n",
    "\n",
    "    #for it to work better\n",
    "    fgmask = cv2.threshold(frameDelta, delta_threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "    fgmask = cv2.dilate(fgmask, None, iterations=2)\n",
    "\n",
    "    contours = cv2.findContours(fgmask.copy(), cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "\n",
    "    #define movement as a function of the contained area by the contour.\n",
    "    mov = False # initialize movement variable\n",
    "    \n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) >= min_area:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            mov = True #if there's movement, change mov to true.\n",
    "    \n",
    "    if (frame - 1) % 1 == 0:\n",
    "        prev_frame = frame_img\n",
    "\n",
    "    frame += frame + 1\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"mask\", fgmask)\n",
    "    cv2.imshow(\"movimiento\", frame_img)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "alpr.unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280.0\n",
      "720.0\n",
      "15.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import imutils\n",
    "\n",
    "#### Abrir webcam (dejándola \"calentar\")\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('carros.avi')\n",
    "# time.sleep(2.0)\n",
    "\n",
    "#### Agrandar la imagen\n",
    "# cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "\n",
    "#### Revisar características de la imagen\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "delta_threshold = 10\n",
    "min_area = 2800\n",
    "\n",
    "\n",
    "cuadro = 1\n",
    "cuadro_anterior = None\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start = time.time()\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        small_frame = imutils.resize(frame, height=357)\n",
    "        gray_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurred_small_frame = cv2.GaussianBlur(gray_small_frame, (15, 15), 0)\n",
    "\n",
    "        if cuadro == 1:\n",
    "            cuadro_anterior = blurred_small_frame\n",
    "            cuadro += 1\n",
    "            continue\n",
    "\n",
    "        frameDelta = cv2.absdiff(blurred_small_frame, cuadro_anterior)\n",
    "        fgmask = cv2.threshold(frameDelta, delta_threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "        fgmask = cv2.dilate(fgmask, None, iterations=2)\n",
    "        cnts = cv2.findContours(fgmask.copy(), cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "        movimiento = False\n",
    "        for c in cnts:\n",
    "            if cv2.contourArea(c) < min_area:\n",
    "                continue\n",
    "\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(small_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            movimiento = True\n",
    "\n",
    "        cv2.imshow('mask',fgmask)\n",
    "        cv2.imshow('imagen', small_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        \n",
    "        # out.write(frame)\n",
    "\n",
    "        if (cuadro - 1) % 1 == 0:\n",
    "            cuadro_anterior = blurred_small_frame\n",
    "\n",
    "        end = time.time()\n",
    "        \n",
    "        cuadro += 1\n",
    "        \n",
    "        try:\n",
    "            time.sleep(0.5 - (end - start))\n",
    "        except:\n",
    "            pass\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "cap.release()\n",
    "#out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 634)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import re\n",
    "\n",
    "from openalpr import Alpr\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'C')\n",
    "\n",
    "#initialize alpr object.\n",
    "alpr =  Alpr(\"us\", \"/etc/openalpr/openalpr.conf\", \"/usr/local/src/openalpr/openalpr/runtime_data/\")\n",
    "\n",
    "if not alpr.is_loaded():\n",
    "    print(\"Error loading OpenALPR\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize cv2 video object.\n",
    "cap = cv2.VideoCapture(\"carros.avi\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    alpr.unload()\n",
    "    sys.exit(\"No abrió el video\")\n",
    "\n",
    "# parameters.\n",
    "alpr.set_top_n(10)\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "delta_threshold = 10\n",
    "min_area = 2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
    "from similarity.levenshtein import Levenshtein\n",
    "from similarity.qgram import QGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"lJX788\"\n",
    "b = \"IJX768\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distancia lev 2\n"
     ]
    }
   ],
   "source": [
    "levenshtein = Levenshtein()\n",
    "print(\"distancia lev\", levenshtein.distance(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distancia lev n 0.3333333333333333\n",
      "similaridad lev n 0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "normalized_levenshtein = NormalizedLevenshtein()\n",
    "print(\"distancia lev n\", normalized_levenshtein.distance(a,b))\n",
    "print(\"similaridad lev n\", normalized_levenshtein.similarity(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "qgram = QGram(2)\n",
    "print(qgram.distance(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
